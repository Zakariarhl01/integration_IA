import streamlit as st
import pandas as pd
import json 
import os 
import numpy as np

# --- CONFIGURATION (Chemins relatifs au script Streamlit) ---
FINAL_CSV_PATH = "../results/anomalies_non_gerees_final.csv"
METRICS_JSON_PATH = "../results/evaluation_metrics.json" 
DETECTION_STATS_PATH = "../results/detection_stats.json" 

# --- 1. FONCTIONS DE CHARGEMENT DES DONN√âES (AVEC CACHE) ---

@st.cache_data
def load_anomalies_data():
    """
    Charge le fichier CSV des anomalies √† traiter.
    Convertit la colonne 'proba_panne' en float pour le tri et le formatage esth√©tique.
    """
    if not os.path.exists(FINAL_CSV_PATH):
        return pd.DataFrame()
    
    try:
        df = pd.read_csv(FINAL_CSV_PATH)
        
        if 'date_measure' in df.columns:
            df['date_measure'] = pd.to_datetime(df['date_measure'])
            
        # Colonne de risque en % (float) pour le tri et le formatage visuel du dataframe
        if 'proba_panne' in df.columns:
            df['Proba_Panne_Pct'] = (df['proba_panne'].astype(float) * 100).round(2)
        
        df = df.rename(columns={
            'turbine_id': 'ID Turbine',
            'date_measure': 'Date Mesure',
            'anomaly_column': 'Capteur Anormal',
            'anomaly_type': 'Type Anomalie',
            'time_to_failure_days': 'Jours Avant Panne (Sim.)',
        })
        
        return df
    except Exception as e:
        st.error(f"‚ùå Erreur de lecture du fichier {FINAL_CSV_PATH} : {e}")
        return pd.DataFrame()

@st.cache_data
def load_evaluation_metrics():
    """Charge le fichier JSON des m√©triques d'√©valuation du mod√®le."""
    if not os.path.exists(METRICS_JSON_PATH):
        return None
    try:
        with open(METRICS_JSON_PATH, 'r') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"‚ùå Erreur de lecture du fichier {METRICS_JSON_PATH} : {e}")
        return None

@st.cache_data
def load_detection_stats():
    """Charge le fichier JSON des statistiques de d√©tection."""
    if not os.path.exists(DETECTION_STATS_PATH):
        return None
    try:
        with open(DETECTION_STATS_PATH, 'r') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"‚ùå Erreur de lecture du fichier {DETECTION_STATS_PATH} : {e}")
        return None

# --- 2. CHARGEMENT ET INITIALISATION ---

st.set_page_config(layout="wide", page_title="EnergiTech - Tableau de Bord Maintenance Pr√©dictive")

df_alertes = load_anomalies_data()
metrics = load_evaluation_metrics()
stats = load_detection_stats()

st.title("‚ö° EnergiTech - Tableau de Bord Maintenance Pr√©dictive")
st.markdown("Interface d'aide √† la d√©cision pour la priorisation des interventions de maintenance.")


# --- A. RAPPORT DE CONFORMIT√â MOD√àLE A  ---

if metrics:
    with st.expander("üìö Rapport d'√âvaluation Mod√®le A (Conformit√©)", expanded=False):
        
        st.markdown("##### üìà Synth√®se des performances")
        report = metrics['classification_report']
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("Pr√©cision Globale (Accuracy)", f"{metrics['accuracy']:.4f}", help="Pourcentage d'observations correctement class√©es.")
        
        if 'Classe 1 (Panne)' in report:
            panne_metrics = report['Classe 1 (Panne)']
            
            # Utilisation de couleurs pour souligner le Recall (FN) et la Precision (FP)
            col2.metric("Rappel (Recall) - Panne", f"{panne_metrics['recall']:.2f}", 
                        delta_color="inverse", 
                        delta="üéØ Minimiser les FN")
            
            col3.metric("Pr√©cision - Panne", f"{panne_metrics['precision']:.2f}",
                        delta_color="normal", 
                        delta="‚úÖ Minimiser les FP")
            
            col4.metric("F1-Score - Panne", f"{panne_metrics['f1-score']:.2f}", delta="√âquilibre des deux")
            
        st.markdown("##### üìã Matrice de Confusion")
        cm_data = metrics['confusion_matrix']
        cm_df = pd.DataFrame(
            cm_data,
            index=['R√©el: Pas Panne (0)', 'R√©el: Panne (1)'],
            columns=['Pr√©dit: Pas Panne (0)', 'Pr√©dit: Panne (1)']
        )
        st.dataframe(cm_df, use_container_width=True)
        
        st.markdown('---')
        tn, fp, fn, tp = cm_data[0][0], cm_data[0][1], cm_data[1][0], cm_data[1][1]
        
        st.markdown(f"**üî¥ Faux N√©gatifs (FN) :** `{fn}` pannes r√©elles manqu√©es (Risque critique).")
        st.markdown(f"**üü° Faux Positifs (FP) :** `{fp}` fausses alertes (Co√ªt en inspections inutiles).")
    st.markdown("---") 


# --- B. STATISTIQUES DE D√âTECTION BRUTES (Esth√©tique : m√©triques plus visuelles) ---

if stats:
    total_anomalies = stats.get('total_anomalies_detectees', 0)
    filtered_anomalies = len(df_alertes) 
    managed_anomalies = total_anomalies - filtered_anomalies
    total_zero_issues = stats.get('zero_detection_issue', 0)
    
    # Calcul des stats pour le probl√®me de Z√©ro D√©tection
    filtered_zero_issues = df_alertes[df_alertes['Type Anomalie'] == 'zero_detection_issue'].shape[0]
    managed_zero_issues = total_zero_issues - filtered_zero_issues
    
    with st.expander("üìä Synth√®se des Statistiques de D√©tection (Brutes vs G√©r√©es)", expanded=False):
        
        st.info(f"Le pipeline a d√©tect√© **{total_anomalies}** anomalies au total. Seulement **{filtered_anomalies}** sont affich√©es ci-dessous car elles n'ont pas encore √©t√© suivies d'une maintenance.")
        
        col_s1, col_s2, col_s3, col_s4 = st.columns(4)
        
        col_s1.metric(
            label="Anomalies D√©tect√©es (Total)", 
            value=total_anomalies,
            help="Total des cas o√π un capteur a d√©pass√© l'IQR ou a renvoy√© z√©ro."
        )

        col_s2.metric(
            label="Anomalies *G√©r√©es* (Maintenance OK)", 
            value=managed_anomalies,
            delta=f"{(managed_anomalies / total_anomalies * 100):.1f} % trait√©",
            delta_color="normal",
            help="Anomalies pour lesquelles une maintenance est d√©j√† enregistr√©e."
        )
        
        col_s3.metric(
            label="Probl√®mes de 'Z√©ro Capteur' (Total)", 
            value=total_zero_issues,
            help="Nombre total de valeurs enregistr√©es √† z√©ro (avant filtrage)."
        )
        
        col_s4.metric(
            label="Z√©ro Capteur *Actifs*", 
            value=filtered_zero_issues,
            delta_color="inverse",
            delta=f"{filtered_zero_issues} √† traiter",
            help="Cas de 'Z√©ro Capteur' n√©cessitant une intervention."
        )
    st.markdown("---") 


# --- C. ALERTES ET ACTIONS PRIORITAIRES (Tableau Interactif + Esth√©tique) ---

if df_alertes.empty:
    st.info("Le tableau de bord est vide. Ex√©cutez le pipeline via main.py pour g√©n√©rer les donn√©es.")

else:
    
    st.subheader(f"üö® Alertes Actives √† Prioriser ({len(df_alertes)} cas non g√©r√©s)")

    # 1. Widgets interactifs
    col_w1, col_w2, col_w3, col_w4 = st.columns([1, 1, 2, 2])
    
    # S√©lecteur de tri
    sort_option = col_w1.radio(
        "Trier le tableau par :",
        ('Risque de Panne', 'Date'),
        index=0, 
        horizontal=True
    )
    
    # Affichage du Risque Maximal (plus impactant en d√©but de section)
    max_risk_value = df_alertes['Proba_Panne_Pct'].max()
    col_w3.metric(label="Risque Maximal Actif", value=f"{max_risk_value} %", delta="Urgence üî•", delta_color="inverse")
    
    # Champ de recherche
    search_query = col_w4.text_input("üîç Rechercher (ID Turbine, Capteur, Type...) :", value="")

    # 2. Application du tri
    if sort_option == 'Risque de Panne':
        sort_column = 'Proba_Panne_Pct' 
        ascending = False
    else:
        sort_column = 'Date Mesure'
        ascending = False

    df_display = df_alertes.sort_values(by=sort_column, ascending=ascending)
    
    # 3. Application du filtre de recherche s'il y en a une
    if search_query:
        search_query = search_query.lower()
        df_display = df_display[
            df_display['ID Turbine'].astype(str).str.contains(search_query) |
            df_display['Type Anomalie'].str.lower().str.contains(search_query) |
            df_display['Capteur Anormal'].str.lower().str.contains(search_query)
        ]
        col_w3.info(f"{len(df_display)} r√©sultats trouv√©s.")


    # 4. Affichage du tableau interactif complet avec style
    
    # Colonnes finales √† afficher
    columns_to_show = [
        'ID Turbine', 
        'Date Mesure', 
        'Proba_Panne_Pct', 
        'Capteur Anormal', 
        'Type Anomalie', 
        'Jours Avant Panne (Sim.)', 
        'technician_id'
    ]
    
    # R√®gle de style : appliquer une couleur d√©grad√©e √† la colonne de probabilit√©
    styled_df = df_display[columns_to_show].style.background_gradient(
        cmap='RdYlGn_r', 
        subset=['Proba_Panne_Pct'], 
        vmin=df_alertes['Proba_Panne_Pct'].min(), 
        vmax=df_alertes['Proba_Panne_Pct'].max()
    ).format({
        'Proba_Panne_Pct': "{:.2f} %" 
    }).set_table_styles([
        {'selector': 'th', 'props': [('background-color', '#007bff'), ('color', 'white')]} 
    ])
    
    # Affichage du dataframe stylis√©
    st.dataframe(
        styled_df,
        use_container_width=True,
        height=400,
    )
    
    st.caption("Le tri par d√©faut est bas√© sur le Risque de Panne. Les couleurs indiquent la criticit√© (Rouge = Urgence, Vert = Moins Critique).")